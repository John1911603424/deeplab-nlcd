{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kjLRNcukss3w",
        "Z7_CzAsZuN9w",
        "0y9o0TFItNZA",
        "cOWfOykYun8T",
        "bOCVtk0PwCmG",
        "xOezR36zx3kE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS4LWOtvO-mK",
        "colab_type": "text"
      },
      "source": [
        "# Introduction #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyMG82wmPHKB",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows how to produce predictions from Sentinel-2 L1C imagery using any of a number of models found in the [geotrellis/deeplab-nlcd](https://github.com/geotrellis/deeplab-nlcd) repository.\n",
        "\n",
        "Any of the \"binary\" (one class, yes/no) networks in the [architectures](https://github.com/geotrellis/deeplab-nlcd/tree/master/python/architectures) directory should work.  Those include architectures whose names contain the substring \"-binary\", as well as networks whose names contain the substring \"sentinel2\".  The former group of architectures also require a \"weights.pth\" file (trained using the [training script](https://github.com/geotrellis/deeplab-nlcd/blob/master/python/train.py) either by you or someone else), the latter group of architectures require no weights file because they are just spectral indices with no parameters.\n",
        "\n",
        "The \"Manual Preparation\" section shows you how to produce predictions one-at-a-time, the \"Batch Preparation\" section shows you how to produce them in bulk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWNVeQAMxntl",
        "colab_type": "text"
      },
      "source": [
        "# Manual Preparation #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLRNcukss3w",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisites ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWib-XGOnfBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install rasterio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmJYIUCDnFBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "import rasterio as rio\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7_CzAsZuN9w",
        "colab_type": "text"
      },
      "source": [
        "## Mount (colab only) ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DopMlpjPpm9p",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y9o0TFItNZA",
        "colab_type": "text"
      },
      "source": [
        "## Load Sentinel-2 L1C Imagery ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nmcwKnoppOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagery_path = '/content/gdrive/My Drive/data/imagery.tif'\n",
        "\n",
        "with rio.open(imagery_path) as ds:\n",
        "  profile = copy.copy(ds.profile)\n",
        "  imagery_data = ds.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1JV-lhqqLFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red = imagery_data[3,:,:] / 4500.0\n",
        "green = imagery_data[2,:,:] / 4500.0\n",
        "blue = imagery_data[1,:,:] / 4500.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0lP6926r5M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red = np.clip(red, 0.0, 1.0)\n",
        "green = np.clip(green, 0.0, 1.0)\n",
        "blue = np.clip(blue, 0.0, 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwNHvMQNscLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "red = (red * 255).astype(np.uint8)\n",
        "green = (green * 255).astype(np.uint8)\n",
        "blue = (blue * 255).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkOw2PqFrPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PIL.Image.fromarray(np.stack([red, green, blue], axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOWfOykYun8T",
        "colab_type": "text"
      },
      "source": [
        "## Load Architecture ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2KihZFIurPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_text(uri: str):\n",
        "    parsed = urlparse(uri)\n",
        "    if parsed.scheme.startswith('http'):\n",
        "        return requests.get(uri).text\n",
        "    else:\n",
        "        with codecs.open(uri, encoding='utf-8', mode='r') as f:\n",
        "            return f.read()\n",
        "\n",
        "def load_architecture(uri: str):\n",
        "    arch_str = read_text(uri)\n",
        "    arch_code = compile(arch_str, uri, 'exec')\n",
        "    exec(arch_code, globals())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlhIg1c3u_vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This can be replaced with other architectures\n",
        "architecture = 'https://raw.githubusercontent.com/geotrellis/deeplab-nlcd/055b6f42f9042d5d443a0f93fbb7f7ae952b3706/python/architectures/cheaplab-regression-binary.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3z10gLUvbaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_architecture(architecture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOCVtk0PwCmG",
        "colab_type": "text"
      },
      "source": [
        "## Make Model, Load Weights ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUvOXkehwGaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backend = 'cpu' # 'cuda' can also be used\n",
        "device = torch.device(backend)\n",
        "band_count = 13 # XXX\n",
        "input_stride = 1\n",
        "class_count = 1\n",
        "divisor = 1\n",
        "\n",
        "model = make_model(\n",
        "    band_count,\n",
        "    input_stride=input_stride,\n",
        "    class_count=class_count,\n",
        "    divisor=divisor,\n",
        "    pretrained=False,\n",
        ").to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KzQ0T5qw9l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = '/content/gdrive/My Drive/data/weights.pth'\n",
        "\n",
        "if not hasattr(model, 'no_weights'):\n",
        "    model.load_state_dict(torch.load(\n",
        "        weights, map_location=device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOezR36zx3kE",
        "colab_type": "text"
      },
      "source": [
        "## Inference ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9Q9dg9rxUK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 64\n",
        "width = profile.get('width')\n",
        "height = profile.get('height')\n",
        "predictions = np.zeros((1, height, width), dtype=np.float32)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_offset in range(0, width, window_size):\n",
        "        if x_offset + window_size > width:\n",
        "            x_offset = width - window_size - 1\n",
        "        for y_offset in range(0, height, window_size):\n",
        "            if y_offset + window_size > height:\n",
        "                y_offset = height - window_size - 1\n",
        "            window = imagery_data[0:band_count, y_offset:y_offset+window_size, x_offset:x_offset+window_size].astype(np.float32)\n",
        "            tensor = torch.from_numpy(np.stack([window], axis=0)).to(device)\n",
        "            out = model(tensor)\n",
        "            if isinstance(out, dict):\n",
        "                out = out['2seg']\n",
        "                out = out.cpu().numpy()\n",
        "            else:\n",
        "                out = out.cpu().numpy()\n",
        "            predictions[:, y_offset:y_offset+window_size, x_offset:x_offset+window_size] = out[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6JmUF1KHEmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_min = np.min(predictions)\n",
        "pred_max = np.max(predictions)\n",
        "pred_uint8 = (np.clip((predictions - pred_min) / (pred_max - pred_min), 0.0, 1.0) * 255).astype(np.uint8)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TMWNGCAM8qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PIL.Image.fromarray(pred_uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LHLbYMcNXXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpTdwAczNZwl",
        "colab_type": "text"
      },
      "source": [
        "## Save ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAR9EtcuNa2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "profile.update(dtype = np.float32, count=1, compress='lzw', predictor=2)\n",
        "\n",
        "predictions_path = '/content/gdrive/My Drive/data/prediction.tif'\n",
        "\n",
        "with rio.open(predictions_path, 'w', **profile) as ds:\n",
        "  ds.write(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7PmYMNHQxgr",
        "colab_type": "text"
      },
      "source": [
        "# Batch Preparation #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3kqJRrRHoF",
        "colab_type": "text"
      },
      "source": [
        "### Step 1 ###\n",
        "\n",
        "Clone the [`geotrellis/deeplab-nlcd`](https://github.com/geotrellis/deeplab-nlcd) repository to a local directory.\n",
        "\n",
        "Type\n",
        "```\n",
        "git clone git@github.com:geotrellis/deeplab-nlcd.git\n",
        "```\n",
        "or similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jU1JL0rRdkl",
        "colab_type": "text"
      },
      "source": [
        "### Step 2 ###\n",
        "\n",
        "Enter the root of the repository directory.\n",
        "\n",
        "Type\n",
        "```\n",
        "cd deeplab-nlcd\n",
        "```\n",
        "or similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Xl4F6yRwoN",
        "colab_type": "text"
      },
      "source": [
        "### Step 3 ###\n",
        "\n",
        "Start a docker container with the needed dependencies.\n",
        "\n",
        "Type\n",
        "```\n",
        "docker run -it --rm -w /workdir -v $HOME/.aws:/root/.aws:ro -v $(pwd):/workdir -v $HOME/Desktop:/desktop --runtime=nvidia jamesmcclain/aws-batch-ml:9 bash\n",
        "```\n",
        "or similar.  This sample command line will mount the local directory `~/Desktop/` which is assumed to contain the imagery on which we wish to work.  We will see later that it is also possible to use imagery on S3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwEBtI00TC39",
        "colab_type": "text"
      },
      "source": [
        "You are now within the docker container."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFHeGsJTMes",
        "colab_type": "text"
      },
      "source": [
        "### Step 4 ###\n",
        "\n",
        "Build the native library needed by the Python code, if that library does not already exist:\n",
        "\n",
        "Type\n",
        "```\n",
        "make -C /workdir/src/libchips\n",
        "```\n",
        "or similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0zS3rwLTYDT",
        "colab_type": "text"
      },
      "source": [
        "### Step 5 ###\n",
        "\n",
        "Now perform inference on imagery.\n",
        "\n",
        "Type\n",
        "```\n",
        "python3 /workdir/python/inference.py --architecture https://raw.githubusercontent.com/geotrellis/deeplab-nlcd/055b6f42f9042d5d443a0f93fbb7f7ae952b3706/python/architectures/cheaplab-regression-binary.py --libchips /workdir/src/libchips/libchips.so --bands 1 2 3 4 5 6 7 8 9 10 11 12 13 --inference-img /desktop/imagery/image*.tif --weights /desktop/weights.pth --raw-prediction-img '/desktop/predictions/cheaplab/*' --classes 1 --window-size 64\n",
        "```\n",
        "or similar.\n",
        "\n",
        "Note that `~/Desktop/imagery/` is assumed to contain the imagery (files with names matching the pattern `image*.tif`) and the directory `~/Desktop/predictions/cheaplab/` is assumed to exist.\n",
        "\n",
        "Note that the single quote around the argument to `--raw-prediction-img` are required to prevent the shell from trying to interpret the `*`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haKpotU8Uhat",
        "colab_type": "text"
      },
      "source": [
        "You are done.  Your predictions can now be found in `~/Desktop/predictions/cheaplab/`.  You can also do predictions on remote assets on S3 by typing\n",
        "```\n",
        "python3 /workdir/python/inference.py --architecture https://raw.githubusercontent.com/geotrellis/deeplab-nlcd/055b6f42f9042d5d443a0f93fbb7f7ae952b3706/python/architectures/cheaplab-regression-binary.py --libchips /workdir/src/libchips/libchips.so --bands 1 2 3 4 5 6 7 8 9 10 11 12 13 --inference-img s3://my-bucket/imagery/image*.tif --weights /desktop/weights.pth --raw-prediction-img 's3://my-bucket/predictions/cheaplab/*' --classes 1 --window-size 64\n",
        "```\n",
        "or similar.\n",
        "\n",
        "You can also mix-and-match locations: you can have remote imagery and save the predictions locally, you can have local imagery and save the predictions to S3.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR70KvNnVB0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}